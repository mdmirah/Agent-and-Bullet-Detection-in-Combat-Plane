{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n"
      ],
      "metadata": {
        "id": "JgrdD1UMxdfW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8s11Fu9v-Qb",
        "outputId": "8c9ac30b-e11a-4c34-c2ac-cc30b13a6b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/552.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m542.7/552.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.5/852.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for multi_agent_ale_py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n",
            "\t/usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/et.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\n",
            "Done!\n",
            "Requirement already satisfied: pettingzoo in /usr/local/lib/python3.11/dist-packages (1.25.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install pettingzoo[atari] supersuit moviepy gymnasium==1.1.1 imageio ffmpeg-python -q\n",
        "!pip install pettingzoo[atari] supersuit stable-baselines3[extra] moviepy imageio ffmpeg-python -q\n",
        "!pip install autorom[accept-rom-license] -q\n",
        "!AutoROM --accept-license\n",
        "!pip install shimmy>=2.0 -q\n",
        "!pip install --upgrade pettingzoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNjF_ttswLAM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pettingzoo.atari import combat_plane_v2\n",
        "import supersuit as ss\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "from pettingzoo.utils.conversions import aec_to_parallel\n",
        "from pettingzoo.utils.wrappers.base import BaseWrapper\n",
        "from pettingzoo.utils.wrappers.base_parallel import BaseParallelWrapper\n",
        "import pettingzoo.utils.env"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AK Functions"
      ],
      "metadata": {
        "id": "nW_N_IQhxkwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AK: R channel function"
      ],
      "metadata": {
        "id": "Ua1WkdUifhx6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sce418MOW3pv"
      },
      "outputs": [],
      "source": [
        "def get_cleaned_R(observation):\n",
        "    \"\"\"\n",
        "    Extracts the R channel from the observation and zeroes out known scoreboard regions.\n",
        "\n",
        "    Parameters:\n",
        "        observation (ndarray): A (256, 160, 3) observation image.\n",
        "\n",
        "    Returns:\n",
        "        R_cleaned (ndarray): A (256, 160) array with scoreboard regions set to 0.\n",
        "    \"\"\"\n",
        "    R = observation[:, :, 0].copy()\n",
        "\n",
        "    # Zero out first_0's scoreboard (rows 4:14, cols 32:44)\n",
        "    R[4:14, 32:44] = 0\n",
        "\n",
        "    # Zero out second_0's scoreboard (rows 4:14, cols 87:99)\n",
        "    R[4:14, 112:124] = 0\n",
        "\n",
        "    return R"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AK: Toroidal distance functions"
      ],
      "metadata": {
        "id": "i-E7aTwOfn0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrhoRVQFwPAw"
      },
      "outputs": [],
      "source": [
        "def toroidal_distance(pos1, pos2, max_row, max_col):\n",
        "    if pos1 is None or pos2 is None:\n",
        "        return None  # Distance undefined if any position missing\n",
        "\n",
        "    d_row = abs(pos1[0] - pos2[0])\n",
        "    d_col = abs(pos1[1] - pos2[1])\n",
        "\n",
        "    # Wrap around for rows\n",
        "    if d_row > max_row / 2:\n",
        "        d_row = max_row - d_row\n",
        "    # Wrap around for cols\n",
        "    if d_col > max_col / 2:\n",
        "        d_col = max_col - d_col\n",
        "\n",
        "    return np.sqrt(d_row**2 + d_col**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24s-K3GYgJ8D"
      },
      "outputs": [],
      "source": [
        "def toroidal_mean(coords, max_row, max_col):\n",
        "    \"\"\"\n",
        "    Compute the mean (row, col) on a toroidal (periodic) grid.\n",
        "    Handles wraparound when averaging coordinates.\n",
        "    \"\"\"\n",
        "    if not coords:\n",
        "        return None\n",
        "\n",
        "    rows = np.array([c[0] for c in coords])\n",
        "    cols = np.array([c[1] for c in coords])\n",
        "\n",
        "    # Convert to complex numbers on the unit circle\n",
        "    row_angles = rows / max_row * 2 * np.pi\n",
        "    col_angles = cols / max_col * 2 * np.pi\n",
        "\n",
        "    mean_row_angle = np.angle(np.mean(np.exp(1j * row_angles)))\n",
        "    mean_col_angle = np.angle(np.mean(np.exp(1j * col_angles)))\n",
        "\n",
        "    # Map back to 0–max range\n",
        "    mean_row = (mean_row_angle % (2 * np.pi)) / (2 * np.pi) * max_row\n",
        "    mean_col = (mean_col_angle % (2 * np.pi)) / (2 * np.pi) * max_col\n",
        "\n",
        "    return (int(round(mean_row)) % max_row, int(round(mean_col)) % max_col)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AK: Find plane position function"
      ],
      "metadata": {
        "id": "SZi1vbk0Z0L-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpPmSpBrZSlr"
      },
      "outputs": [],
      "source": [
        "def find_plane_position(R, target_value):\n",
        "    \"\"\"\n",
        "    Finds the average (row, col) position of all 4x2 uniform blocks of a given target_value in R.\n",
        "    Parameters:\n",
        "        R (ndarray): 2D array of R channel values with scoreboard regions removed.\n",
        "        target_value (int): The value to search for (223 for first_0, 111 for second_0).\n",
        "    Returns:\n",
        "        (row, col): Tuple of integer coordinates (averaged) or None if not found.\n",
        "    \"\"\"\n",
        "    positions = []\n",
        "\n",
        "    for row in range(R.shape[0] - 3):      # Stop at row 252 to allow 4-row box\n",
        "        for col in range(R.shape[1] - 1):  # Stop at col 158 to allow 2-col box\n",
        "            submatrix = R[row:row+4, col:col+2]\n",
        "\n",
        "            if np.all(submatrix == target_value):\n",
        "                # Take the (3rd row, 2nd col) = (row + 2, col + 1)\n",
        "                positions.append((row + 2, col + 1))\n",
        "\n",
        "    if positions:\n",
        "        return toroidal_mean(positions, R.shape[0], R.shape[1])\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AK: Offensive reward function"
      ],
      "metadata": {
        "id": "niFplstefyXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_HRPXIyq13K"
      },
      "outputs": [],
      "source": [
        "class OffensiveRewardWrapper(BaseWrapper):\n",
        "    def __init__(self, env, shoot_actions=None, reward_multiplier=5, shoot_bonus=0.1):\n",
        "        super().__init__(env)\n",
        "        self.shoot_actions = shoot_actions or {1, 10, 11, 12, 13, 14, 15, 16, 17}\n",
        "        self.reward_multiplier = reward_multiplier\n",
        "        self.shoot_bonus = shoot_bonus\n",
        "        self.first_0_step_count = 0  # Counter for first_0 steps\n",
        "\n",
        "    def step(self, action):\n",
        "        agent = self.agent_selection\n",
        "        super().step(action)\n",
        "\n",
        "        if agent == \"first_0\" and agent in self.agents:\n",
        "            self.first_0_step_count += 1  # Increment step count\n",
        "\n",
        "            original = self.rewards[agent]\n",
        "            if original > 0:\n",
        "                self.rewards[agent] = original * self.reward_multiplier\n",
        "                #print(f\"[REWARD DEBUG] {agent} hit: reward {original:.3f} → {self.rewards[agent]:.3f}\")\n",
        "\n",
        "            if self.first_0_step_count % 5 == 0:\n",
        "                observation = self.env.observe(agent)\n",
        "                R = get_cleaned_R(observation)\n",
        "\n",
        "                first_pos = find_plane_position(R, 223)\n",
        "                second_pos = find_plane_position(R, 111)\n",
        "\n",
        "                #print(f\"[DEBUG] first_0 position: {first_pos}, second_0 position: {second_pos}\")\n",
        "                #print(f\"[REWARD DEBUG] {agent} used action {action}\")\n",
        "\n",
        "                if action in self.shoot_actions:\n",
        "                    self.rewards[agent] += self.shoot_bonus\n",
        "                    #print(f\"[REWARD DEBUG] {agent} used action {action} on step {self.first_0_step_count}, +{self.shoot_bonus:.3f} → total: {self.rewards[agent]:.3f}\")\n",
        "\n",
        "                # Proximity reward\n",
        "                max_toroidal_dist = 151.6\n",
        "                min_dist = 10\n",
        "                max_score = 0.5\n",
        "\n",
        "                dist = toroidal_distance(first_pos, second_pos, R.shape[0], R.shape[1])\n",
        "                if dist is not None:\n",
        "                    clamped_dist = max(min_dist, min(dist, max_toroidal_dist))\n",
        "                    proximity_reward = max_score * (max_toroidal_dist - clamped_dist) / (max_toroidal_dist - min_dist)\n",
        "                    self.rewards[agent] += proximity_reward\n",
        "                    #print(f\"[REWARD DEBUG] {agent} proximity distance {dist:.2f}, reward +{proximity_reward:.3f} → total: {self.rewards[agent]:.3f}\")\n",
        "                else:\n",
        "                    #print(f\"[REWARD DEBUG] {agent} proximity distance unknown (position obscured)\")\n",
        "                    pass\n",
        "\n",
        "            if self.first_0_step_count % 5 == 0:\n",
        "                print(f\"[OFFFENSIVE] Step: {self.first_0_step_count}, Reward: {self.rewards[agent]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MR Functions"
      ],
      "metadata": {
        "id": "5uCrgBqgDpsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MR: Defensive reward function"
      ],
      "metadata": {
        "id": "Y6C-hBrpgIdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DefensiveRewardWrapper(BaseWrapper):\n",
        "    def __init__(self, env, bullet_value=255, bullet_block_size=2):\n",
        "        super().__init__(env)\n",
        "        self.bullet_value = bullet_value\n",
        "        self.bullet_block_size = bullet_block_size\n",
        "        self.first_0_step_count = 0\n",
        "\n",
        "        self.action_labels = {\n",
        "            0: \"No operation\", 1: \"Fire\", 2: \"Move up\", 3: \"Move right\",\n",
        "            4: \"Move left\", 5: \"Move down\", 6: \"Move upright\", 7: \"Move upleft\",\n",
        "            8: \"Move downright\", 9: \"Move downleft\", 10: \"Fire up\", 11: \"Fire right\",\n",
        "            12: \"Fire left\", 13: \"Fire down\", 14: \"Fire upright\", 15: \"Fire upleft\",\n",
        "            16: \"Fire downright\", 17: \"Fire downleft\"\n",
        "        }\n",
        "\n",
        "    def step(self, action):\n",
        "        agent = self.agent_selection\n",
        "        super().step(action)\n",
        "\n",
        "        if agent != \"first_0\":\n",
        "            return\n",
        "\n",
        "        self.first_0_step_count += 1\n",
        "        action_label = self.action_labels.get(action, \"Unknown\")\n",
        "\n",
        "\n",
        "        # Calculate rewards only every 10 steps\n",
        "        if self.first_0_step_count % 10 != 0:\n",
        "            return\n",
        "\n",
        "        # Get red channel from observation\n",
        "        observation = self.env.observe(agent)\n",
        "        R = get_cleaned_R(observation)\n",
        "\n",
        "        # Detect agent and opponent\n",
        "        first_pos = find_plane_position(R, 223)\n",
        "        second_pos = find_plane_position(R, 111)\n",
        "\n",
        "        # Visualize the observation\n",
        "        visualize_rgb_image(observation, self.first_0_step_count)\n",
        "        visualize_planes(R, self.first_0_step_count)\n",
        "\n",
        "        # Detect all bullets (treat all as dangerous)\n",
        "        bullets = find_bullet_positions(\n",
        "            R,\n",
        "            step_count=self.first_0_step_count,\n",
        "            white_thresh_low=100,\n",
        "            white_thresh_high=255,\n",
        "            min_bullet_area=0.5,\n",
        "            max_bullet_area=1.0,\n",
        "            edge_margin=2,\n",
        "            visualize=True\n",
        "        )\n",
        "\n",
        "        print(f\"[DEFENSIVE AGENT ACTION] Step {self.first_0_step_count}: Agent {agent} took action {action} ({action_label})\")\n",
        "\n",
        "        # 🎯 Initialize reward components\n",
        "        distance_reward = 0.0\n",
        "        bullet_avoidance_reward = 0.0\n",
        "        damage_penalty = 0.0\n",
        "        firing_penalty = 0.0\n",
        "\n",
        "        if first_pos:\n",
        "            # ✅ Distance-from-enemy reward\n",
        "            if second_pos:\n",
        "                max_dist = 151.6\n",
        "                dist = toroidal_distance(first_pos, second_pos, R.shape[0], R.shape[1])\n",
        "                if dist is not None:\n",
        "                    distance_reward = 0.4 * (dist / max_dist)\n",
        "                    self.rewards[agent] += distance_reward\n",
        "\n",
        "            # ✅ Bullet avoidance reward\n",
        "            if bullets:\n",
        "                bullet_distances = [\n",
        "                    toroidal_distance(first_pos, bpos, R.shape[0], R.shape[1])\n",
        "                    for bpos in bullets if bpos is not None\n",
        "                ]\n",
        "                bullet_distances = [d for d in bullet_distances if d is not None]\n",
        "                if bullet_distances:\n",
        "                    closest = min(bullet_distances)\n",
        "                    max_bullet_dist = 151.6\n",
        "                    bullet_avoidance_reward = 0.6 * min(closest / max_bullet_dist, 1.0)\n",
        "                    self.rewards[agent] += bullet_avoidance_reward\n",
        "\n",
        "                # ❌ Damage penalty for getting hit\n",
        "                hit_radius = 3\n",
        "                for bpos in bullets:\n",
        "                    dist_to_self = toroidal_distance(bpos, first_pos, R.shape[0], R.shape[1])\n",
        "                    if dist_to_self is not None and dist_to_self <= hit_radius:\n",
        "                        damage_penalty = -0.6\n",
        "                        self.rewards[agent] += damage_penalty\n",
        "                        break\n",
        "\n",
        "        # ❌ Penalty for firing action\n",
        "        if action in {1, 10, 11, 12, 13, 14, 15, 16, 17}:\n",
        "            firing_penalty = -0.4\n",
        "            self.rewards[agent] += firing_penalty\n",
        "\n",
        "        # Final reward report\n",
        "        print(f\"Step: {self.first_0_step_count}, \"\n",
        "              f\"First Pos: {first_pos}, Second Pos: {second_pos}, \"\n",
        "              f\"\\nDistance Reward: {distance_reward:.4f}, \"\n",
        "              f\"Bullet Avoidance Reward: {bullet_avoidance_reward:.4f}, \"\n",
        "              f\"Damage Penalty: {damage_penalty:.4f}, \"\n",
        "              f\"Firing Penalty: {firing_penalty:.4f}, \"\n",
        "              f\"Total Reward: {self.rewards[agent]:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "909yYOLZ4x_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MR: Find bullet function"
      ],
      "metadata": {
        "id": "TpX1LHlQgD9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_bullet_positions(\n",
        "    R,\n",
        "    step_count=None,\n",
        "    white_thresh_low=245,\n",
        "    white_thresh_high=255,\n",
        "    min_bullet_area=0.5,\n",
        "    max_bullet_area=1,\n",
        "    edge_margin=2,  # ← New parameter to ignore detections near edges\n",
        "    visualize=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Detect bullet positions in R-channel by excluding background, clouds, and edges.\n",
        "\n",
        "    Parameters:\n",
        "        R (np.ndarray): Red channel image.\n",
        "        step_count (int): Optional debug step.\n",
        "        white_thresh_low (int): Minimum R value to consider a bullet.\n",
        "        white_thresh_high (int): Maximum R value (255).\n",
        "        min_bullet_area (int): Minimum contour area to consider.\n",
        "        max_bullet_area (int): Maximum contour area to consider.\n",
        "        edge_margin (int): Number of pixels to exclude near the edge.\n",
        "        visualize (bool): Whether to show debug visualizations.\n",
        "\n",
        "    Returns:\n",
        "        List of (x, y) bullet positions.\n",
        "    \"\"\"\n",
        "    height, width = R.shape[:2]\n",
        "\n",
        "    # Apply intensity filter to extract only very bright pixels\n",
        "    bullet_mask = cv2.inRange(R, white_thresh_low, white_thresh_high)\n",
        "\n",
        "    # Remove small noise\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    bullet_mask = cv2.morphologyEx(bullet_mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(bullet_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    bullet_positions = []\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if min_bullet_area <= area <= max_bullet_area:\n",
        "            M = cv2.moments(cnt)\n",
        "            if M[\"m00\"] != 0:\n",
        "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "\n",
        "                # ✅ Skip detections near the edge\n",
        "                if (edge_margin <= cx < width - edge_margin) and (edge_margin <= cy < height - edge_margin):\n",
        "                    bullet_positions.append((cx, cy))\n",
        "\n",
        "    # ✅ Optional visualization\n",
        "    if visualize:\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "        axs[0].imshow(R, cmap=\"gray\")\n",
        "        axs[0].set_title(f\"R-Channel (Step {step_count})\")\n",
        "\n",
        "        axs[1].imshow(bullet_mask, cmap=\"gray\")\n",
        "        axs[1].set_title(\"Binary Mask (Thresholded)\")\n",
        "\n",
        "        R_copy = cv2.cvtColor(R, cv2.COLOR_GRAY2BGR)\n",
        "        for (cx, cy) in bullet_positions:\n",
        "            cv2.circle(R_copy, (cx, cy), 3, (0, 255, 0), -1)  # Green dot\n",
        "\n",
        "        axs[2].imshow(R_copy)\n",
        "        axs[2].set_title(\"Detected Bullets (Filtered)\")\n",
        "\n",
        "        for ax in axs:\n",
        "            ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Text log\n",
        "    if step_count is not None:\n",
        "        if bullet_positions:\n",
        "            print(f\"[BULLET DETECTION] Step {step_count}: Found {len(bullet_positions)} bullet(s) → {bullet_positions}\")\n",
        "        else:\n",
        "            print(f\"[BULLET DETECTION] Step {step_count}: No bullets detected.\")\n",
        "\n",
        "    return bullet_positions\n"
      ],
      "metadata": {
        "id": "5RQKA4cy4Cdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MR: Visualization functions"
      ],
      "metadata": {
        "id": "BeiH9aYEgMPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_planes(R, step=None):\n",
        "    \"\"\"\n",
        "    Visualizes the red channel and the detected positions of the two planes.\n",
        "\n",
        "    Parameters:\n",
        "        R (ndarray): 2D grayscale red channel image.\n",
        "        step (int, optional): Step count to label the figure.\n",
        "    \"\"\"\n",
        "    # Detect plane positions\n",
        "    first_pos = find_plane_position(R, target_value=223)\n",
        "    second_pos = find_plane_position(R, target_value=111)\n",
        "\n",
        "    # Convert grayscale R to BGR for color annotations\n",
        "    R_bgr = cv2.cvtColor(R, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    if first_pos:\n",
        "        cv2.circle(R_bgr, (first_pos[1], first_pos[0]), 5, (255, 0, 0), -1)  # Blue for first_0\n",
        "        cv2.putText(R_bgr, \"1\", (first_pos[1]+6, first_pos[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
        "\n",
        "    if second_pos:\n",
        "        cv2.circle(R_bgr, (second_pos[1], second_pos[0]), 5, (0, 0, 255), -1)  # Red for second_0\n",
        "        cv2.putText(R_bgr, \"2\", (second_pos[1]+6, second_pos[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(R_bgr)\n",
        "    title = f\"Plane Positions (Step {step})\" if step is not None else \"Plane Positions\"\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "w-BaYsHDXMLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_r_channel(R, step=None, center=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(R, cmap='gray')\n",
        "    if center:\n",
        "        plt.scatter(center[1], center[0], color='red', s=40, label='Agent')\n",
        "        plt.legend()\n",
        "    if step:\n",
        "        plt.title(f\"R-Channel at Step {step}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LYGRR85UNVsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_rgb_image(rgb_image, step=None, title=\"RGB Image\"):\n",
        "    \"\"\"\n",
        "    Displays the full RGB image.\n",
        "\n",
        "    Parameters:\n",
        "        rgb_image (ndarray): A (H, W, 3) RGB image (in standard numpy uint8 format).\n",
        "        step (int, optional): Optional step counter to annotate the plot title.\n",
        "        title (str): Custom title for the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(rgb_image)\n",
        "    plot_title = f\"{title} (Step {step})\" if step is not None else title\n",
        "    plt.title(plot_title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "imBAAjgviZ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AK + MR Hybrid Functions (Optional)"
      ],
      "metadata": {
        "id": "Q3N432g1Dz2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AK + MR: Hybrid reward function"
      ],
      "metadata": {
        "id": "R8f5fKW_u-5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridRewardWrapper(BaseWrapper):\n",
        "    def __init__(self, env, shoot_actions=None,\n",
        "                 proximity_threshold=264, max_proximity_score=0.25,\n",
        "                 hit_multiplier=0.5,\n",
        "                 bullet_value=255, hit_radius=3,\n",
        "                 bullet_proximity_threshold=15, bullet_proximity_penalty_scale=-0.3,\n",
        "                 own_bullet_memory=5):\n",
        "        super().__init__(env)\n",
        "        self.env = env\n",
        "        self.shoot_actions = shoot_actions or {1, 10, 11, 12, 13, 14, 15, 16, 17}\n",
        "        self.proximity_threshold = proximity_threshold\n",
        "        self.max_proximity_score = max_proximity_score\n",
        "        self.hit_multiplier = hit_multiplier\n",
        "        self.bullet_value = bullet_value\n",
        "        self.hit_radius = hit_radius\n",
        "        self.bullet_proximity_threshold = bullet_proximity_threshold\n",
        "        self.bullet_proximity_penalty_scale = bullet_proximity_penalty_scale\n",
        "        self.own_bullet_memory = own_bullet_memory\n",
        "        self.first_0_step_count = 0\n",
        "        self.own_bullet_positions = []\n",
        "\n",
        "        self.action_labels = {\n",
        "            0: \"No operation\", 1: \"Fire\", 2: \"Move up\", 3: \"Move right\",\n",
        "            4: \"Move left\", 5: \"Move down\", 6: \"Move upright\", 7: \"Move upleft\",\n",
        "            8: \"Move downright\", 9: \"Move downleft\", 10: \"Fire up\", 11: \"Fire right\",\n",
        "            12: \"Fire left\", 13: \"Fire down\", 14: \"Fire upright\", 15: \"Fire upleft\",\n",
        "            16: \"Fire downright\", 17: \"Fire downleft\"\n",
        "        }\n",
        "\n",
        "    def step(self, action):\n",
        "        agent = self.agent_selection\n",
        "        super().step(action)\n",
        "\n",
        "        if agent != \"first_0\" or agent not in self.agents:\n",
        "            return\n",
        "\n",
        "        self.first_0_step_count += 1\n",
        "        observation = self.env.observe(agent)\n",
        "        R = get_cleaned_R(observation)\n",
        "\n",
        "        # Detect plane positions\n",
        "        first_pos = find_plane_position(R, 223)\n",
        "        second_pos = find_plane_position(R, 111)\n",
        "\n",
        "        # Visualize the observation\n",
        "        visualize_rgb_image(observation, self.first_0_step_count)\n",
        "        visualize_planes(R, self.first_0_step_count)\n",
        "\n",
        "        # Detect all bullets\n",
        "        bullets = find_bullet_positions(\n",
        "            R,\n",
        "            step_count=self.first_0_step_count,\n",
        "            white_thresh_low=100,\n",
        "            white_thresh_high=255,\n",
        "            min_bullet_area=0.5,\n",
        "            max_bullet_area=1.0,\n",
        "            edge_margin=2,\n",
        "            visualize=True\n",
        "        )\n",
        "\n",
        "        # 🎯 Reward components\n",
        "        proximity_reward = 0.0\n",
        "        hit_reward = 0.0\n",
        "        bullet_proximity_penalty = 0.0\n",
        "        damage_penalty = 0.0\n",
        "\n",
        "        # ✅ Track own bullet firing position\n",
        "        if action in self.shoot_actions and first_pos:\n",
        "            self.own_bullet_positions.append({\n",
        "                \"pos\": first_pos,\n",
        "                \"step\": self.first_0_step_count\n",
        "            })\n",
        "\n",
        "        # ⏳ Remove expired own bullets\n",
        "        self.own_bullet_positions = [\n",
        "            b for b in self.own_bullet_positions\n",
        "            if self.first_0_step_count - b[\"step\"] <= self.own_bullet_memory\n",
        "        ]\n",
        "\n",
        "        # 🔍 Filter out self bullets\n",
        "        enemy_bullets = []\n",
        "        for bpos in bullets:\n",
        "            if all(toroidal_distance(bpos, ob[\"pos\"], R.shape[0], R.shape[1]) > 5\n",
        "                   for ob in self.own_bullet_positions):\n",
        "                enemy_bullets.append(bpos)\n",
        "\n",
        "        # ✅ Proximity reward (offensive)\n",
        "        if first_pos and second_pos:\n",
        "            dist = toroidal_distance(first_pos, second_pos, R.shape[0], R.shape[1])\n",
        "            if dist is not None and dist < self.proximity_threshold:\n",
        "                proximity_reward = self.max_proximity_score * (self.proximity_threshold - dist) / self.proximity_threshold\n",
        "                self.rewards[agent] += proximity_reward\n",
        "\n",
        "        # ✅ Hit reward (amplified)\n",
        "        original = self.rewards[agent]\n",
        "        if original > 0:\n",
        "            hit_reward = original * self.hit_multiplier\n",
        "            self.rewards[agent] += hit_reward\n",
        "\n",
        "        # ❌ Bullet proximity penalty (enemy bullets only)\n",
        "        if first_pos and enemy_bullets:\n",
        "            distances = [toroidal_distance(first_pos, bpos, R.shape[0], R.shape[1]) for bpos in enemy_bullets]\n",
        "            distances = [d for d in distances if d is not None]\n",
        "            if distances:\n",
        "                closest = min(distances)\n",
        "                if closest <= self.bullet_proximity_threshold:\n",
        "                    bullet_proximity_penalty = self.bullet_proximity_penalty_scale * (\n",
        "                        (self.bullet_proximity_threshold - closest) / self.bullet_proximity_threshold\n",
        "                    )\n",
        "                    self.rewards[agent] += bullet_proximity_penalty\n",
        "\n",
        "        # ❌ Damage penalty (enemy bullets only)\n",
        "        if first_pos:\n",
        "            for bpos in enemy_bullets:\n",
        "                dist_to_self = toroidal_distance(first_pos, bpos, R.shape[0], R.shape[1])\n",
        "                if dist_to_self is not None and dist_to_self <= self.hit_radius:\n",
        "                    damage_penalty = -1.0\n",
        "                    self.rewards[agent] += damage_penalty\n",
        "                    break\n",
        "\n",
        "        # 🖨️ Final reward breakdown\n",
        "        action_label = self.action_labels.get(action, \"Unknown\")\n",
        "        print(f\"[HYBRID] Step {self.first_0_step_count}, Agent: {agent} took action {action} ({action_label})\")\n",
        "        print(f\"→ First Pos: {first_pos}, Second Pos: {second_pos}\")\n",
        "        print(f\"→ Proximity Reward: +{proximity_reward:.4f}\")\n",
        "        print(f\"→ Hit Reward Multiplier: +{hit_reward:.4f}\")\n",
        "        print(f\"→ Bullet Proximity Penalty: {bullet_proximity_penalty:.4f}\")\n",
        "        print(f\"→ Damage Penalty: {damage_penalty:.4f}\")\n",
        "        print(f\"→ Total Reward: {self.rewards[agent]:.4f}\\n\")\n",
        "        print(f\"[DEBUG] Own bullets tracked: {[ob['pos'] for ob in self.own_bullet_positions]}\")\n",
        "        print(f\"[DEBUG] Enemy bullets: {enemy_bullets}\")"
      ],
      "metadata": {
        "id": "tPa36YVWu-r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codes"
      ],
      "metadata": {
        "id": "IEH09gtbxqNf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efM5JMOZwNJS"
      },
      "outputs": [],
      "source": [
        "# Supersuit Documentation\n",
        "# https://pettingzoo.farama.org/api/wrappers/supersuit_wrappers/\n",
        "\n",
        "# Create the base PettingZoo AEC environment\n",
        "env = combat_plane_v2.env(render_mode='rgb_image',game_version='bi-plane', guided_missile=False) # Other option is 'human'\n",
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpsVBOwcBvqI"
      },
      "outputs": [],
      "source": [
        "# env = OffensiveRewardWrapper(env) # Offensive Agent\n",
        "env = DefensiveRewardWrapper(env) # Defensive Agent\n",
        "# env = HybridRewardWrapper(env) # Hybrid Agent\n",
        "env.reset()\n",
        "\n",
        "env = ss.color_reduction_v0(env, mode='B')\n",
        "env = ss.resize_v1(env, x_size=84, y_size=84)\n",
        "env = ss.frame_stack_v1(env, 4)\n",
        "env = ss.black_death_v3(env)\n",
        "env.reset()\n",
        "\n",
        "env = aec_to_parallel(env)\n",
        "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "env = ss.concat_vec_envs_v1(env, 4, num_cpus=1, base_class='stable_baselines3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTSM_n71eX4G"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=100,            # Save every 100,000 timesteps\n",
        "    save_path=\"MARL/MARL.ipynb\",         # Save to the ./models directory\n",
        "    name_prefix=\"ppo_offensive_round3\"     # Models will be saved as ppo_biplane_XXXXX_steps.zip\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPh0dPwWedGz"
      },
      "outputs": [],
      "source": [
        "model = PPO(\"CnnPolicy\", env, n_steps= 768, batch_size=256, verbose=1)\n",
        "model.learn(total_timesteps=10000, callback=checkpoint_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output"
      ],
      "metadata": {
        "id": "ItawnrZJ0VCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "qXGqfNPG0ZFL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5gDMu62xQFk"
      },
      "outputs": [],
      "source": [
        "model = PPO.load(\"/home/aydenkemp/MARL/MARL/MARL.ipynb/ppo_offensive_round2_719984_steps.zip\", env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ENDTIfkH_Ww",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Read video file\n",
        "mp4 = open(\"/content/combat_plane_ai_vs_random.mp4\", 'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "# Render inline HTML video player\n",
        "HTML(f\"\"\"\n",
        "<video width=480 controls>\n",
        "  <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzjW0pBSNJgI"
      },
      "outputs": [],
      "source": [
        "#OLD\n",
        "\n",
        "test_env = combat_plane_v2.env(render_mode=\"rgb_array\", game_version=\"bi-plane\", guided_missile=False) # Other option is 'human'\n",
        "test_env = ss.color_reduction_v0(test_env, mode='B')\n",
        "test_env = ss.resize_v1(test_env, x_size=84, y_size=84)\n",
        "test_env = ss.frame_stack_v1(test_env, 4)\n",
        "test_env = ss.black_death_v3(test_env)\n",
        "test_env.reset()\n",
        "\n",
        "frames = []\n",
        "rewards = []\n",
        "MAX_FRAMES = 10000\n",
        "\n",
        "for step, agent in enumerate(test_env.agent_iter()):\n",
        "    if step >= MAX_FRAMES:\n",
        "        break\n",
        "    obs, reward, terminated, truncated, _ = test_env.last()\n",
        "    if agent == \"first_0\":\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "    else:\n",
        "        action = test_env.action_space(agent).sample()\n",
        "    test_env.step(action)\n",
        "    frames.append(Image.fromarray(test_env.render()))\n",
        "    rewards.append(reward)\n",
        "\n",
        "video_path = \"/content/combat_plane_ai_vs_random.mp4\"\n",
        "imageio.mimsave(video_path, frames, fps=15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}